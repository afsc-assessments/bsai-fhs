rm(mod2020)
## length bins to use for fsh and srv length comp data
max_size <- max(mod_2020$lbins) ##65 = rex ##70 = Dover and Flathead
min_size <- min(mod_2020$lbins)
bin_width <- 2
len_bins <- mod_2020$lbins#c(seq(min_size,max_size,bin_width),43,46,49,52,55,58)
lapply(list.files(here('sql'), full.names = T), source) ## load all sql queries
# DATA DOWNLOAD ----
#* AKFIN Catches ----
message("Querying AKFIN to get catch...")
catch <- sqlQuery(AKFIN,qcatch) %>% arrange(YEAR, ZONE, GEAR)
qcatch
lapply(list.files(here('sql'), full.names = T), source) ## load all sql queries
lapply(list.files(here('2023','sql'), full.names = T), source) ## load all sql queries
catch <- sqlQuery(AKFIN,qcatch) %>% arrange(YEAR, ZONE, GEAR)
write.csv(catch, file=here(year,'data','raw',paste0(Sys.Date(),'-catch.csv') ), row.names=FALSE)
#* AFSC observer catches ----
message("Querying haul-level catch from observer DB...")
catches_observer <- sqlQuery(AFSC,qcatch_obs)
catches_observer$ID <- paste(catches_observer$CRUISE, catches_observer$PERMIT,catches_observer$HAUL, sep="_")
catches_observer$SPECIES <- ifelse(catches_observer$SPECIES==103, 'flathead_sole', 'Bering_flounder')
catches_observer <- select(catches_observer, -CRUISE, -PERMIT, -HAUL) %>%
rename(species=SPECIES, year=YEAR, weight=EXTRAPOLATED_WEIGHT,
gear=GEAR_TYPE, area=NMFS_AREA, pct.retained=PERCENT_RETAINED)
saveRDS(catches_observer, file = here(year,'data','raw',paste0(Sys.Date(),'-catches_observer.RDS') ))
write.csv(catches_observer, file=here(year,'data','raw',paste0(Sys.Date(),'-catches_observer.csv') ), row.names=FALSE)
index_ebs <-  read.csv(paste0(data_folder,date_use,"-biomass_survey_ebs.csv")) %>%
select(year=YEAR, biomass=BIOMASS,
variance=VARBIO) %>% cbind(survey='ebs')
## This only includes FHS b/c no BF found there
message("Querying AI survey biomass data...")
ai <- sqlQuery(AFSC, qsurvAI)
if(!is.data.frame(ai)) stop("Failed to query AI survey data")
write.csv(ai, file=here(year,'data','raw',paste0(Sys.Date(),'-biomass_survey_ai.csv') ), row.names=FALSE)
#* Survey biomass (NBS, for illustration only)  ----
test <- sqlQuery(AFSC, qnbs)
if(!is.data.frame(test)) stop("Failed to query NBS survey data")
write.csv(test, here(year,'data','raw',paste0(Sys.Date(),'-biomass_survey_nbs_by_species.csv')), row.names=FALSE)
index_ebs <-  read.csv(paste0(data_folder,date_use,"-biomass_survey_ebs.csv")) %>%
select(year=YEAR, biomass=BIOMASS,
variance=VARBIO) %>% cbind(survey='ebs')
data_folder = here('data','/')
data_folder = here('data','raw')
index_ebs <-  read.csv(paste0(data_folder,date_use,"-biomass_survey_ebs.csv")) %>%
select(year=YEAR, biomass=BIOMASS,
variance=VARBIO) %>% cbind(survey='ebs')
index_ebs <-  read.csv(paste0(data_folder,"-biomass_survey_ebs.csv")) %>%
select(year=YEAR, biomass=BIOMASS,
variance=VARBIO) %>% cbind(survey='ebs')
data_folder =
index_ebs <-  read.csv(here('data','raw',"-biomass_survey_ebs.csv")) %>%
select(year=YEAR, biomass=BIOMASS,
variance=VARBIO) %>% cbind(survey='ebs')
data_folder =
index_ebs <-  read.csv(here('data','raw',"2023-12-19-biomass_survey_ebs.csv")) %>%
select(year=YEAR, biomass=BIOMASS,
variance=VARBIO) %>% cbind(survey='ebs')
#* Survey biomass (EBS Shelf) ----
message("Querying EBS survey biomass data...")
test <- sqlQuery(AFSC, qsurv)
if(!is.data.frame(test)) stop("Failed to query EBS survey data")
write.csv(test, file=here(year,'data','raw',paste0(Sys.Date(),'-biomass_survey_ebs.csv') ), row.names=FALSE)
test <- sqlQuery(AFSC, qsurvspp)
if(!is.data.frame(test)) stop("Failed to query EBS survey data")
write.csv(test, here(year,'data','raw',paste0(Sys.Date(),'-biomass_survey_ebs_by_species.csv')), row.names=FALSE)
data_folder =
index_ebs <-  read.csv(here('data','raw',"2023-12-19-biomass_survey_ebs.csv")) %>%
select(year=YEAR, biomass=BIOMASS,
variance=VARBIO) %>% cbind(survey='ebs')
index_ai <- read.csv(here('data','raw','2023-12-19-biomass_survey_ai.csv')) %>%
mutate(species=gsub(" ", "_",COMMON_NAME)) %>%
select(year=YEAR, biomass=TOTAL_BIOMASS,
variance=BIOMASS_VAR) %>% cbind(survey='AI')
here('data','raw','2023-12-19-biomass_survey_ai.csv')
read.csv(here('data','raw','2023-12-19-biomass_survey_ai.csv'))
index_ai <- read.csv(here('data','raw','2023-12-19-biomass_survey_ai.csv')) %>%
mutate(species=gsub(" ", "_",COMMON_NAME)) %>%
select(year=YEAR, biomass=TOTAL_BIOMASS,
variance=BIOMASS_VAR) %>% cbind(survey='AI')
data_folder =
index_ebs <-  read.csv(here(year,'data','raw',"2023-12-19-biomass_survey_ebs.csv")) %>%
select(year=YEAR, biomass=BIOMASS,
variance=VARBIO) %>% cbind(survey='ebs')
index_ai <- read.csv(here(year, 'data','raw','2023-12-19-biomass_survey_ai.csv')) %>%
mutate(species=gsub(" ", "_",COMMON_NAME)) %>%
select(year=YEAR, biomass=TOTAL_BIOMASS,
variance=BIOMASS_VAR) %>% cbind(survey='AI')
index_raw <- rbind(index_ebs, index_ai) %>%
pivot_wider(names_from=survey, values_from=c(biomass, variance))
## Do a linear regression to get missing AI years
index_raw  <- index_raw %>% mutate(sd_ebs=sqrt(variance_ebs), sd_AI=sqrt(variance_AI))
interpyr <- index_raw$year[which(is.na(index_raw$biomass_AI))]
z1 <- subset(index_raw, !is.na(biomass_AI))
z2 <- subset(index_raw, is.na(biomass_AI))
lmbio <- lm(biomass_AI~biomass_ebs, data=z1)
z2$biomass_AI <- as.numeric(predict(lmbio, newdata=z2))
lmvar <- lm(sd_AI~sd_ebs, data=z1)
z2$sd_AI <- as.numeric(predict(lmvar, newdata=z2)
## Recombine and add together biomass and variances
index <- rbind(z1,z2) %>% group_by(year) %>%
## Recombine and add together biomass and variances
index <- rbind(z1,z2) %>% group_by(year) %>%
summarize(biomass=round(biomass_AI+biomass_ebs,5),
variance=sd_AI^2+sd_ebs^2,
.groups='drop') %>%
## SE on log scale, which SS requires, is sqrt(log(1+CV^2))
mutate(se_log=round(sqrt(log(1+variance/biomass^2)),5)) %>%
select(-variance)
SS_index <- data.frame(year=index$year, seas=7, index=2, obs=index$biomass, se_log=index$se_log)
write.csv(x=SS_index, file= here(year,'data','output',paste0(Sys.Date(),'-SS_survey_index.csv')) , row.names=FALSE)
index
index$se_log
index_raw
?sum
## Recombine and add together biomass and variances
index <- rbind(z1,z2) %>% group_by(year) %>%
summarize(biomass=round(biomass_AI+biomass_ebs,5),
variance=sum(sd_AI^2,sd_ebs^2,na.rm = TRUE),
.groups='drop') %>%
## SE on log scale, which SS requires, is sqrt(log(1+CV^2))
mutate(se_log=round(sqrt(log(1+variance/biomass^2)),5)) %>%
select(-variance)
index
SS_index <- data.frame(year=index$year, seas=7, index=2,
obs=index$biomass, se_log=index$se_log)
write.csv(x=SS_index, file= here(year,'data','output',paste0(Sys.Date(),'-SS_survey_index.csv')) , row.names=FALSE)
## Recombine and add together biomass and variances
index <- rbind(z1,z2) %>% group_by(year) %>%
summarize(biomass=round(biomass_AI+biomass_ebs,5),
variance=sum(sd_AI^2,sd_ebs^2,na.rm = TRUE),
.groups='drop') %>%
## SE on log scale, which SS requires, is sqrt(log(1+CV^2))
mutate(se_log=round(sqrt(log(1+variance/biomass^2)),5)) %>%
select(-variance)
# message("Querying EBS age-length...")
# ## Query written by Rebecca Haehn in 2020 based on a really old
# ## version by Dan. This replaces the need to use her dropbox .csv
# ## file.
query <- "SELECT a.hauljoin, d.year, a.region, a.specimenid, a.biostratum, a.species_code, a.length, a.weight, a.sex,
a.age, b.start_time, b.bottom_depth, b. stratum, b.gear_temperature, b.bottom_type, b.gear_depth, b.performance,
b.duration, b.distance_fished, b.net_width, b.net_height, b.net_measured, b.start_latitude, b.end_latitude,
b.start_longitude, b.end_longitude, b.surface_temperature, b.gear, b.abundance_haul, c.nmfs_area,
decode(b.stratum,10,1,20,2,31,3,32,3,41,4,42,4,43,4,50,5,61,6,62,6,82,8,90,9,-9) subarea
from RACEBASE.SPECIMEN a
inner join RACEBASE.HAUL b
on a.hauljoin = b.hauljoin
inner join haehnr.ebs_nmfs_areas c
on b.stationid = c.stationid
left join HAULNAME d
on a.hauljoin = d.hauljoin
where a.region = 'BS' and
species_code in (10130, 10140) and
b.abundance_haul = 'Y';
"
test <- sqlQuery(AFSC, query)
if(!is.data.frame(test)) stop("Failed to query age-length survey data")
sqlQuery(AFSC, query)
low.nmfs.area <- "'500'" #"'600'" #500
hi.nmfs.area <- "'544'" #"'699'"  #544
SpeciesCode = "103"
## Potentially unbury the choices for FmpArea for max flexibility.
FmpArea <- "'BS'" #Options are 'AI' = 539-544 'GOA' = 600 to 699 'BS' = 500 to 539
source('data/get_lcomps_fishery.R')
library(afscdata)
# globals ----
year = 2024
## you must be on the VPN for this to work
DBI::dbConnect(odbc::odbc(), 'AKFIN', uid = 'mkapur', pwd = 'ssmamk22')
connect <- function(db = "akfin") {
# check if database name is stored in keyring, if not request user/pwd
if(!(db %in% keyring::key_list()[,1])) {
user <- getPass::getPass(paste("Enter", db, "username: "))
pwd <- getPass::getPass(paste("Enter", db, "password: "))
} else {
user <- keyring::key_list(db)$username
pwd <-  keyring::key_get(db, keyring::key_list(db)$username)
}
# connect to server
DBI::dbConnect ( odbc::odbc(),
db,
uid = user,
pwd = pwd )
}
#' utility function to disconnect from se
connect()
## you must be on the VPN for this to work
DBI::dbConnect(odbc::odbc(), 'AKFIN', uid = 'mkapur', pwd = 'ssmamk22')
DBI::dbConnect(odbc::odbc(), 'AKFIN', uid = 'mkapur', pwd = 'mPw5!kqN23w')
## you must be on the VPN for this to work
DBI::dbConnect(odbc::odbc(), 'AFSC', uid = 'mkapur', pwd = 'mPw5!kqN23w')
## you must be on the VPN for this to work
DBI::dbConnect(odbc::odbc(), 'afsc', uid = 'mkapur', pwd = 'mPw5!kqN23w')
library(odbc)
remove.packages('odbc')
read.csv(here(year,'data','raw','2022-12-19-catch.csv'))
library(r4ss)
library(here)
library(dplyr)
library(r4ss)
library(here)
library(dplyr)
colvec <- c("dodgerblue4", "#ffb703","#219ebc", "#023047",  "#fb8500")
year <- 2024
old_mdl_fldr <- here::here(year,'mgmt','18.2c_2020')
mod18.2c_2020 <- mod_2020 <- SS_output(old_mdl_fldr, verbose = FALSE)
read.csv(here(year,'data','raw','2022-12-19-catch.csv'))
read.csv(here(year,'data','raw','2023-12-19-catch.csv'))
read.csv(here(year,'data','raw','fsh_catch_data.csv'))
oldc <- read.csv(here(year,'data','raw','2023-12-19-catch.csv'))
newc <- read.csv(here(year,'data','raw','fsh_catch_data.csv'))
newc <- read.csv(here(year,'data','raw','fsh_catch_data.csv'))
``
dim(oldc)
dim(newc)
names(newc)
names(oldc)
qsurv
lapply(list.files(here('2023','sql'), full.names = T), source) ## load all sql queries
fsh_sp_area <- "'BS','AI'"              # FMP
fsh_sp_label <- "'FSOL'"                # AKFIN group species label
fsh_sp_str <- "103"                     # AKFIN species code
lapply(list.files(here('2023','sql'), full.names = T), source) ## load all sql queries
final_year <- 2024
fsh_sp_area <- "'BS','AI'"              # FMP
fsh_sp_label <- "'FSOL'"                # AKFIN group species label
fsh_sp_str <- "103"                     # AKFIN species code
fsh_start_yr <- 1977                    # start year
sp_area <- "'BS'"                       #
## length bins to use for fsh and srv length comp data
max_size <- max(mod_2020$lbins) ##65 = rex ##70 = Dover and Flathead
min_size <- min(mod_2020$lbins)
bin_width <- 2
len_bins <- mod_2020$lbins#c(seq(min_size,max_size,bin_width),43,46,49,52,55,58)
lapply(list.files(here('2023','sql'), full.names = T), source) ## load all sql queries
qcatch
View(oldc)
View(newc)
afscassess::clean_catch
library(afscdata)
library(afscassess)
library(r4ss)
library(dplyr)
library(here)
library(ggplot2)
theme_set(afscassess::theme_report())
# globals ----
year = 2024
rec_age = 0 ## this is default for SS3
plus_age = 21
lengths = c(seq(6,40,2),seq(43,58,3))
TAC = c(25000, 25000, 35500) # 2021, 2022, 2023
#species = "FSOL"
species
species = "FSOL"
# fishery catch (note: this automates the in-year estimation)
## output/yld_ratio.csv has the expansion factor ($ratio) and the 3-year catch/TAC ratio ($yld)
## which are used for in-year and next-two-year catches, respectively
suppressWarnings(afscassess::clean_catch(year = year,
species = species,
TAC = TAC))
vroom::vroom(here::here(year,'data','raw','fsh_catch_data.csv'))
catch_to_ss <- function(year, catch_data, se = 0.01, season = 7, fleet=1){
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch, catch_se = se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
}
catch_to_ss <- function(year, se = 0.01, season = 7, fleet=1){
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch, catch_se = se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
}
catch_to_ss(year)
catch_to_ss <- function(year, se = 0.01, season = 7, fleet=1){
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch, catch_se = se) %>%
select(year, seas, fleet, catch, catch_se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
}
catch_to_ss(year)
catch_to_ss <- function(year, se = 0.01, season = 7, fleet=1, round = FALSE){
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch = ifelse(round, round(catch),catch), catch_se = se) %>%
select(year, seas, fleet, catch, catch_se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
}
catch_to_ss(year, round = TRUE)
catch_to_ss <- function(year, se = 0.01, season = 7, fleet=1, round_t = FALSE){
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch = ifelse(round_t, round(catch),catch), catch_se = se) %>%
select(year, seas, fleet, catch, catch_se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
}
catch_to_ss(year, round = TRUE)
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch = ifelse(round_t, round(catch),catch), catch_se = se) %>%
select(year, seas, fleet, catch, catch_se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7, fleet, catch = ifelse(round_t, round(catch),catch), catch_se = 0.01) %>%
select(year, seas, fleet, catch, catch_se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7, fleet=1, catch = ifelse(round_t, round(catch),catch), catch_se = 0.01) %>%
select(year, seas, fleet, catch, catch_se)
round_t = T
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7, fleet=1, catch = ifelse(round_t, round(catch),catch), catch_se = 0.01) %>%
select(year, seas, fleet, catch, catch_se)
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7, fleet=1, catch_t =
ifelse(round_t, round(catch),catch),
catch_se = 0.01) %>%
select(year, seas, fleet, catch, catch_se)
catch_to_ss <- function(year, se = 0.01, season = 7, fleet=1, round_t = FALSE){
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch_t = ifelse(round_t, round(catch),catch), catch_se = se) %>%
select(year, seas, fleet, catch, catch_se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
}
catch_to_ss(year, round = TRUE)
round_t
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7, fleet=1, catch_t =
ifelse(round_t, round(catch),catch),
catch_se = 0.01)
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7, fleet=1, catch_t = round(catch),
catch_se = 0.01) %>%
select(year, seas, fleet, catch, catch_se)
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7, fleet=1, catch_t = round(catch),
catch_se = 0.01) %>%
select(year, seas, fleet, catch_t, catch_se)
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7,
fleet=1,
catch_t = if(round_t == FALSE, catch, round(catch)),
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = 7,
fleet=1,
catch_t = ifelse(round_t == FALSE, catch, round(catch)),
catch_se = 0.01) %>%
select(year, seas, fleet, catch_t, catch_se)
catch_to_ss <- function(year, se = 0.01, season = 7, fleet=1){
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch_t = round(catch), catch_se = se) %>%
select(year, seas, fleet, catch, catch_se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
}
catch_to_ss(year)
catch_to_ss <- function(year, se = 0.01, season = 7, fleet=1){
vroom::vroom(here::here(year,'data','output','fsh_catch.csv')) %>%
mutate(seas = season, fleet, catch_t = round(catch), catch_se = se) %>%
select(year, seas, fleet, catch_t, catch_se) %>%
vroom::vroom_write(here::here(year, "data", "output", "fsh_catch_ss3.csv"), delim = ",")
}
catch_to_ss(year)
# bottom trawl survey biomass
afscassess::bts_biomass(year = year,
rmv_yrs = c(1984, 1987))
afscassess::bts_biomass
afscassess::bts_biomass(area = 'bsai', year = year,
rmv_yrs = c(1984, 1987))
afscassess::bts_biomass(area = 'bsai',
file = here::here(year, 'data','raw','bts_biomass_data.csv'),
year = year,
rmv_yrs = c(1984, 1987))
here()
here::here(year, 'data','raw','bts_biomass_data.csv')
afscassess::bts_biomass(area = 'bsai',
file = here::here(year, 'data','raw','bts_biomass_data.csv'),
year = year,
rmv_yrs = c(1984, 1987))
View(afscassess::bts_biomass)
afscassess::bts_biomass(area = 'bsai',
year = year,
rmv_yrs = c(1984, 1987))
plus_age
rec_age
lengths
afscassess::bts_biomass
afscassess::clean_catch
# fishery catch (note: this automates the in-year estimation)
## output/yld_ratio.csv has the expansion factor ($ratio) and the 3-year catch/TAC ratio ($yld)
## which are used for in-year and next-two-year catches, respectively
suppressWarnings(afscassess::clean_catch(year = year,
species = species,
TAC = TAC,
fixed_catch = here::here('data','user_input','bsai_fhs_catch_1964_1994.rda')))
# fishery catch (note: this automates the in-year estimation)
## output/yld_ratio.csv has the expansion factor ($ratio) and the 3-year catch/TAC ratio ($yld)
## which are used for in-year and next-two-year catches, respectively
suppressWarnings(afscassess::clean_catch(year = year,
species = species,
TAC = TAC,
fixed_catch = here::here(year,'data','user_input','bsai_fhs_catch_1964_1994.rda')))
afscassess::clean_catch
# fishery catch (note: this automates the in-year estimation)
## output/yld_ratio.csv has the expansion factor ($ratio) and the 3-year catch/TAC ratio ($yld)
## which are used for in-year and next-two-year catches, respectively
suppressWarnings(afscassess::clean_catch(year = year,
species = species,
TAC = TAC,
fixed_catch = 'bsai_fhs_catch_1964_1994.rda'))
# fishery catch (note: this automates the in-year estimation)
## output/yld_ratio.csv has the expansion factor ($ratio) and the 3-year catch/TAC ratio ($yld)
## which are used for in-year and next-two-year catches, respectively
suppressWarnings(afscassess::clean_catch(year = year,
species = species,
TAC = TAC,
fixed_catch = 'bsai_fhs_catch_1964_1994.csv'))
#devtools::install_github("afsc-assessments/afscdata", force = TRUE)
#devtools::install_github("BenWilliams-NOAA/afscassess", force = TRUE)
#devtools::install_github('r4ss/r4ss', force = TRUE)
library(afscdata)
library(afscassess)
library(r4ss)
library(dplyr)
library(here)
library(ggplot2)
theme_set(afscassess::theme_report())
# globals ----
year = 2024
rec_age = 0 ## this is default for SS3
plus_age = 21
lengths = c(seq(6,40,2),seq(43,58,3))
TAC = c(25000, 25000, 35500) # 2021, 2022, 2023
species = "FSOL"
#curr_mdl_fldr = "2020.1-2023"
#prev_mdl_fldr = "2020.1-2021"
#mdl_name = "model_20_1"
#dat_name = "goa_po
# fishery catch (note: this automates the in-year estimation)
## output/yld_ratio.csv has the expansion factor ($ratio) and the 3-year catch/TAC ratio ($yld)
## which are used for in-year and next-two-year catches, respectively
suppressWarnings(afscassess::clean_catch(year = year,
species = species,
TAC = TAC,
fixed_catch = 'bsai_fhs_catch_1964_1994.csv'))
afscassess::clean_catch
fc = read.csv(here('data','user_input','bsai_fhs_catch_1964_1994.csv'))
fc = read.csv(here(year,'data','user_input','bsai_fhs_catch_1964_1994.csv'))
View(afscassess::clean_catch)
years = (year - 3):(year - 1)
yr = year
if (sum(TAC == c(3333, 2222, 1111)) == 3) {
stop("check your TAC!")
}
fc
names(fc) <- c("year", "catch")
catch_data <- vroom::vroom(here::here(year, "data", "raw",
"fsh_catch_data.csv"))
catch_data
obs_data <- vroom::vroom(here::here(year, "data", "raw",
"fsh_obs_data.txt"), delim = ",", col_type = c(join_key = "c",
haul_join = "c"))
rat <- obs_data %>% tidytable::filter(year %in% years) %>%
tidytable::mutate(tot_catch = sum(extrapolated_weight,
na.rm = T), test_date = lubridate::`year<-`(max(catch_data$week_end_date),
year), .by = year) %>% tidytable::filter(haul_date <=
test_date) %>% tidytable::summarise(oct_catch = round(sum(extrapolated_weight,
na.rm = T)), tot_catch = round(mean(tot_catch)), .by = year) %>%
tidytable::summarise(ratio = 1 + (sum(tot_catch) - sum(oct_catch))/sum(oct_catch))
nrow(fc) >= 1
if (nrow(fc) >= 1) {
catch <- catch_data %>% tidytable::select(year, catch = weight_posted) %>%
tidytable::filter(year > max(fc$year)) %>% tidytable::summarise(catch = round(sum(catch),
4), .by = year) %>% tidytable::bind_rows(fc) %>%
tidytable::arrange(year)
}
catch
if (nrow(fc) >= 1) {
catch <- catch_data %>% tidytable::select(year, catch = weight_posted) %>%
tidytable::filter(year > max(fc$year)) %>% tidytable::summarise(catch = round(sum(catch),
4), .by = year) %>% tidytable::bind_rows(fc) %>%
tidytable::arrange(year)
}
else {
years
yield <- catch %>% tidytable::filter(year %in% years) %>%
tidytable::bind_cols(tac = TAC) %>% tidytable::summarise(yld = mean(catch/tac))
yld <- catch %>% tidytable::filter(year == yr) %>% tidytable::mutate(proj_catch = catch *
rat$ratio) %>% tidytable::bind_cols(rat, yield)
if (!(is.null(alt))) {
vroom::vroom_write(catch, here::here(year, alt, "output",
"fsh_catch.csv"), delim = ",")
vroom::vroom_write(yld, here::here(year, alt, "output",
"yld_rat.csv"), delim = ",")
catch
}
alt
catch
vroom::vroom_write(catch, here::here(year, "data", "output",
"fsh_catch.csv"), delim = ",")
# fishery catch (note: this automates the in-year estimation)
## output/yld_ratio.csv has the expansion factor ($ratio) and the 3-year catch/TAC ratio ($yld)
## which are used for in-year and next-two-year catches, respectively
suppressWarnings(afscassess::clean_catch(year = year,
species = species,
TAC = TAC,
fixed_catch = 'bsai_fhs_catch_1964_1994.csv'))
## reformat catches
afscdata::catch_to_ss(year)
afscdata::catch_to_ss
catch_to_ss(year)
catch_to_ss(year, seas = 1, fleet = 1)
afscassess::bts_biomass
afscassess::bts_biomass(area = 'bsai',
year = year)
library(readr)
bsai_total_bts_biomass_data <- read_csv("2024/data/raw/bsai_total_bts_biomass_data.csv")
View(bsai_total_bts_biomass_data)
