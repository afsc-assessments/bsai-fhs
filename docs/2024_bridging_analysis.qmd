---
title: "2024 BSAI FHS Bridging Analyses"
author: "Maia Kapur maia.kapur@noaa.gov"
format: html
editor: source
toc: true
toc-depth: 2
---

```{r, include = FALSE, warning = FALSE, message = FALSE}
library(r4ss)
library(here)
library(dplyr)
library(ggplot2)
theme_set(afscassess::theme_report())

colvec <- c("dodgerblue4", "#ffb703","#219ebc", "#023047",  "#fb8500")

year <- 2024
old_mdl_fldr <- here::here(year,'mgmt','18.2c_2020')
mod18.2c_2020 <- mod_2020 <- SS_output(old_mdl_fldr, verbose = FALSE)
```

# Overview

This electronic document describes the analyses undertaken to bridge the last "full" assessment of BSAI Flathead Sole (Monnahan, 2020) into the latest Stock Synthesis (SS3) software version, as well as explorations of sequential inclusion of recent data.

The general workflow was as follows:

1)  Move the 2020 model, referred to as Model 18.2c (2020), from SS3 version 3.30.16 to the the newest SS3 software version as of December 2023 (3.30.22) downloaded from the [NOAA Virtual Lab](https://github.com/nmfs-ost/ss3-source-code/releases). Comparisons between model derived quantities and likelihoods given this change are provided in this document. 

2)  Compare the historical and newly-pulled data. The "old data pull approach" used code from Drs. McGilliard & Monnahan originating from a local R package entitled `newsbss`, which is highly customized and not actively maintained. The "newly-pulled" data are obtained using a combination of the `afscdata` and `gapindex` packages (the former for fishery data, the latter for survey data). This is the preferred approach since these packages are actively maintained and provide a unified approach for many stocks. To confirm things looked right, I ran the 2020 model with *only* individual (historical) data sources changed, to convince myself that trivial differences in the raw data extraction were indeed trivially impactful.

3)  Sequentially bridge the data. Model 18.2c (2020) has catches and fishery length comps through 2020, and everything else through 2019. We added catches through 2023, with an estimate of 2024 catches, then survey abundance indices, then survey lengths, then survey CAALs (marginal ages are ghosted, but included as well), then fishery lengths, then fishery ages. The impact of each of these five steps is documented below. **This bridged model, with updated software and data inputs but no structural changes is labeled as Model 18.2c (2024)**.

```{r include = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Data used in model Model 18.2c (2020). Most of these will be updated with at least 3 years of data for the bridged model, with the exception of fishery age compositions; there was not enough age-reader time to complete otolith reads for 2022 and 2023 (more details below). Also note that while there are fishery length data for most of the time series, fitting to these data is disabled in years where fishery ages are available."}
SSplotData(mod18.2c_2020, subplots = 2)
```

# Stock Synthesis Software Update 3.30.22 

```{r include = FALSE, echo = FALSE,  warning = FALSE, message = FALSE}
mod18.2c_2020_v33022 <- SS_output(here::here(year,'model_runs','18.2c_2020_ss3v33022'), verbose = FALSE)
ss_compare <- SSsummarize(list(mod18.2c_2020,mod18.2c_2020_v33022))
```

## Warnings

Model 18.2c (2020) had generic warnings about the `recr_dist` method, poor $F_{MSY}$ convergence, and an issue with the final gradient. Only the latter is of concern. Model 18.2c run with the new SS3 software threw the same warnings as well as an indication that the initial value for `parm 11` was greater than the max (`999 > 5`); this is the end logit parameter for double-normal survey selex (forcing it to be asymptotic). I am comfortable with the consistency of these warnings and clean them up below; the gradient is identical between models (`r  mod18.2c_2020$maximum_gradient_component`).

## Likelihood Components

```{r include = TRUE, echo = FALSE,  warning = FALSE, message = FALSE}
names(ss_compare$likelihoods)[c(1,2)] <- c('Model 18.2c (2020)', 'Model 18.2c (2020) - software transition')
ss_compare$likelihoods[c(1:7,11),]
SSplotComparisons(ss_compare, print = T, plotdir = here('docs','ss_version_bridge'), legendlabels = names(ss_compare$likelihoods)[c(1,2)], col = colvec)
```

::: panel-tabset
## Spawning Biomass

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="The spawning biomass trajectory and associated uncertainty are identical between models"}
knitr::include_graphics(here::here('docs','ss_version_bridge','compare2_spawnbio_uncertainty.png'))
```

## Survey Fits

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="Survey fits are identical between models"}
knitr::include_graphics(here::here('docs','ss_version_bridge','compare13_indices.png'))
```

## Recruitment Time Series

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="The recruitment time series and associated uncertainty are identical between models"}
knitr::include_graphics(here::here('docs','ss_version_bridge','compare10_recruits_uncertainty.png'))
```

## Unfished Recruitment

```{r, include=T, echo = FALSE, warning = FALSE,fig.cap="The R0 posteriors are identical between models"}
knitr::include_graphics(here::here('docs','ss_version_bridge','compare16_densities_SR_LN(R0).png'))
```
:::

## SS3 Bridging Conclusion

Based on the above explorations, I am comfortable that moving to the latest SS3 version is not impacting model behavior. After completing this exercise, I addressed the `warnings` in the latest model via the following:

-   Change `recr_dist_method` to 4 (line 17) and removing associated stuff lines 99-101
-   Change the `INIT` for Age_DblN_end_logit_Survey to 20 and the MAX to 25 to get rid of the bound error. The selectivity is the same.

The warning-free model is in `model_runs/18.2c_2020_ss3v33022w`. I use this warning-free model to do the data explorations in the next section.

```{r include = FALSE, message = FALSE, warning = FALSE}
m18.2cv33022w <- SS_output(here::here(year,'model_runs','18.2c_2020_ss3v33022w'), verbose = FALSE)
SSplotSelex(m18.2cv33022w, fleets = 2, sexes = 1)
```

# Data Exploration

## Big-Picture Data Notes

This section of the script assumes that one has already downloaded and formatted the data one plans to use in the assesssment. To avoid separate scripts doing the same thing, I'm completing that step in `R/2024_analysis.R`, with a `source()` call to `R/bsai_fhs_wrangle_data`. I wrote some functions for the `afscdata` and `afscassess` packages that reshape those data frames into the SS3 format, which is also accomplished in that script.

Bering Flounder is *not* included in the compositional data; Dr. Monnahan caught and corrected this issue in 2020. The total survey biomass and catches do include both species.

### Age-Read triaging

**Due to staffing issues** we had to reduce the number of otoliths read for all sources in years 2022 and 2023. After consulting with the Age & Growth team, they indicated they could read a *total* of about 750 BSAI FHS otoliths this year. This is a considerable reduction (\~75%) given that normally we have about 600-800 otoliths for each source (survey and fishery) for each year. We normally read every collected otolith from each source, so there are not historical ratios to use for guidance.

The two alternatives in this situation were to 1) disregard the fishery age-comps from 2022 & 2023 for this assessment, and devote all reading effort to the survey or 2) find a compromise (split) among the two fleets and years that doesn't amount to simply adding noise to the model.

The figures below illustrate simulated composition data at varying levels of age-reads which I generated to determine the best way forward. We evaluated the resultant datasets based on how distinct they appeared from the full dataset. Our findings were as follows:

-   Simply splitting the 750 otoliths evenly across years & fleets (187 reads each) results in a mis-represented plus group for the survey.
-   Based on the data weights in the 2020 model, and the fact that survey CAALs are used to inform growth, it's intuitively preferable to assign more otolith reads to the survey data. This could range from completely ignoring the fishery data for these years to forming some sort of compromise among the datasets.
-   The data weights would suggest that 2.5x the number of otoliths should be read from the survey (equaling 267 survey otoliths per year). This approach results in satisfactory compositions for the survey but not for the fishery.
-   A compromise between these two approaches, shown in blue below, where the survey gets 225 age-reads per year, and the fishery gets 175 age-reads per year, result in satisfactory compositions for the survey but risk missing young fish from the fishery. 

After considering these results, Dr. Kapur decided in January 2024 to go with the very first option and **assign all available reader time to the survey**, with the understanding that a) the A&G program could finish reading the leftover fishery otoliths for future assessment years, and b) we don't expect these simulated datasets to have a strong influence on the terminal derived quantities given that recruitment deviations are set to zero for the last three years.


::: panel-tabset
### Otolith Collections thru Time

```{r eval = TRUE, echo = FALSE, include = TRUE, message = FALSE, warning = FALSE, fig.cap = "Historical numbers of Bering Sea otoliths collected and read, by source. Survey collections from the AI remain unread. There is variation in the proportion of collected fishery otoliths that were read through time. The survey has consistently read nearly all collected otoliths. The red bars are the proposed number of age-reads for 2022 and 2023 data."}
## note that I changed the "collected" column so that only the difference between collected & aged is peeking out

otodat <- read.csv(here::here(year,'data','user_input','otolith_reads_vs_aged.csv')) %>%

  mutate(Collected_plot = Collected-Aged,
         proportion = ifelse(Aged ==0 |is.na(Collected),'',round(Aged/Collected,2))) %>%
    select(-region, -effN_mod2020,-Collected) %>%
  reshape2::melt(id = c('Year','source', 'proportion')) %>%
  mutate(variable = forcats::fct_relevel(variable, c('Collected_plot','Aged'))) 
  ggplot(otodat, aes(x = Year, y = value, fill = variable, color = variable )) +
    geom_bar(position = 'stack', stat = 'identity', width = 1) +
  labs(x = 'Year', y = 'Number of Otoliths', fill = '', color = '') +
  scale_color_manual(values = c('grey77','dodgerblue2'), labels = c('Collected','Aged'))+
  scale_fill_manual(values = c('grey77','dodgerblue2'), labels = c('Collected','Aged'))+
    scale_x_continuous(expand = c(0,0))+
  facet_grid(source~.)+
          geom_bar(data = subset(otodat, Year>2021 & variable == 'Aged'),position = 'stack', stat = 'identity', width = 1, fill = 'red', color = 'red') 

```

### Simulated Fishery Ages

```{r eval = TRUE, echo = FALSE, include = TRUE, message = FALSE, warning = FALSE, fig.cap = "Experimental visualization of simulated fishery age-comp data using fewer otolith reads."}
## visualize the comps data with fewer samples
obs_fsh_19<-  subset(mod_2020$agedbase, Yr == 2019 & Sex == 1 & Fleet == 1) %>% select(Obs) %>% unlist()
sim600 <- rmultinom(n  = 1, prob= obs_fsh_19, size = 600 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.))))
sim187 <- rmultinom(n  = 1, prob= obs_fsh_19, size = 187 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.))))
sim175 <- rmultinom(n  = 1, prob= obs_fsh_19, size = 175 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.))))
sim107 <- rmultinom(n  = 1, prob= obs_fsh_19, size = 107 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.)))) 
p1 <- ggplot(sim600, aes(x = age, y = freq)) +
  geom_area(fill = 'grey55')+   geom_point() + 
  labs(x = 'age',y = 'simulated frequency', title = 'Full Sampling (n = 600)') +
  scale_y_continuous(limits = c(0,0.15))
p2 <-ggplot(sim187, aes(x = age, y = freq)) +
  geom_area(fill = 'grey55')+   geom_point() + 
  labs(x = 'age',y = 'simulated frequency', title = 'Equivalent Sampling (n = 187)')+scale_y_continuous(limits = c(0,0.15))

p3 <-ggplot(sim175, aes(x = age, y = freq)) +
  geom_area(fill = 'dodgerblue4')+   geom_point() + 
  labs(x = 'age',y = 'simulated frequency', title = 'Compromise Sampling (n = 175)')+scale_y_continuous(limits = c(0,0.15))

p4 <-ggplot(sim107, aes(x = age, y = freq)) +
  geom_area(fill = 'grey55')+   geom_point() + 
  labs(x = 'age',y = 'simulated frequency', title = 'Data Weighted Sampling (n = 107)')+scale_y_continuous(limits = c(0,0.15)) 

Rmisc::multiplot(plotlist = list(p1,p3,p2, p4), cols = 2)
```

### Simulated Survey Ages

```{r eval = TRUE, echo = FALSE, include = TRUE, message = FALSE, warning = FALSE, fig.cap = "Experimental visualization of simulated survey age-comp data using fewer otolith reads. These are simulated using marginal age comp data from females in 2019."}
## simulate the survey CAALs at lower SS.

obs_srv_19 <-  subset(mod_2020$condbase, Yr == 2019 & Sex == 1 & Fleet == 2) %>% 
  group_by(Bin) %>%
  summarise(mean(Obs)) %>%
  select(Obs = `mean(Obs)`) %>% unlist()

sim600 <- rmultinom(n  = 1, prob= obs_srv_19, size = 600 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.))))
sim187 <- rmultinom(n  = 1, prob= obs_srv_19, size = 187 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.))))

sim225 <- rmultinom(n  = 1, prob= obs_srv_19, size = 225 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.))))
sim267 <- rmultinom(n  = 1, prob= obs_srv_19, size = 267 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.))))
sim50 <- rmultinom(n  = 1, prob= obs_srv_19, size = 50 ) %>%
  data.frame('raw'=.) %>%
  mutate(freq = raw/sum(raw),
         age = as.numeric(gsub('Obs','',rownames(.))))

p1 <- ggplot(sim600, aes(x = age, y = freq)) +
  geom_area(fill = 'grey55')+   geom_point() + 
  labs(x = 'age',y = 'simulated frequency', title =  'Full Sampling (n = 600)') +
  scale_y_continuous(limits = c(0,0.1))
p4 <-ggplot(sim187, aes(x = age, y = freq)) +
  geom_area(fill = 'grey55')+   geom_point() + 
  labs(x = 'age',y = 'simulated frequency', title = 'Equivalent Sampling (n = 187)')+scale_y_continuous(limits = c(0,0.15))
p2 <-ggplot(sim267, aes(x = age, y = freq)) +
  geom_area(fill = 'grey55')+   geom_point() + 
  labs(x = 'age',y = 'simulated frequency', title = 'Data Weighted Sampling (n = 267)')+scale_y_continuous(limits = c(0,0.15))
 

p3 <- ggplot(sim225, aes(x = age, y = freq)) +
  geom_area(fill = 'dodgerblue4')+   geom_point() + 
  labs(x = 'age',y = 'simulated frequency', title = 'Compromise Sampling (n = 225)')+scale_y_continuous(limits = c(0,0.15))

Rmisc::multiplot(plotlist = list(p1,p3,p2, p4), cols = 2)
```
:::

## Fishery Catches

Both queries call from the `council.comprehensive_blend_ca` table. I ran the `afscassess::clean_catch()` function on the downloaded data, and the summary code for aggregating into tons. **The approaches result in consistent catch histories,** with the understandable exception of in-year catches for 2020 (which were under-estimated).

```{r load dfs, include = TRUE, echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}
## Aggregate catch to just year

rbind( mod_2020$catch %>% select(Yr, Obs) %>%
         mutate(src = 'Old'),
       read.csv(here(year,'data','output','fsh_catch_ss3.csv')) %>% mutate(src = 'New') %>% select(Yr = year, Obs = catch_t, src) ) %>%
  ggplot(., aes(x = Yr, y = Obs, col = src )) +
  geom_line() +
  scale_color_manual(values = c('blue','grey22'),
                     labels = c('2024 Model Data', '2020 Model Data'))+
  labs(x = 'Year', y = 'Observed Catch (t)', color = '') +
  geom_vline(data = NULL, aes(xintercept = 2020), linetype = 'dotted', color = 'grey66')

```

## Fishery Length Compositions

```{r, include=FALSE, echo = FALSE, warning = FALSE}
mod_2020_new_fsh_age_comps <- SS_output(here(year, 'model_runs','18.2c_2020_ss3v33022w-new_fsh_age_comps'))
mod_2020_new_fsh_len_comps <- SS_output(here(year, 'model_runs','18.2c_2020_ss3v33022w-new_fsh_len_comps'))
compsummary_1 <- SSsummarize(list(mod_2020,mod_2020_new_fsh_age_comps))
compsummary_2 <- SSsummarize(list(mod_2020,mod_2020_new_fsh_len_comps))
```

*I was unable to reproduce the fishery age- and len-comp routine* used for the older version of the model. For reproducibility purposes, I am going to move towards the `afscdata` approach, which requires about 10% of the code to run, and does not require multiple reads of the same data sources. Importantly, I tested Model 18.2c with *only* the age-comp or len-comp data (separately) changed to those available using my new approach and found the impact on derived quantities to be trivial.

The current assessment passes the fishery length comp time series but only fits to data in years where there are not age-comp data (1977-1999, 2002-2003, 2008 and 2020). Note that the new data pull routine only gets values from 1988 onwards, so values before that are unchanged.

::: panel-tabset
### Fish Len Comps from 18.c (2020)

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="By manual inspection of the values and data plots, the outcomes are very similar, but not identical. It appears there is a slight squashing of observations towards older ages; the input sample sizes are essentially unchanged." }
SSplotComps(mod_2020, kind = 'LEN', fleets = 1, subplots = 1, datonly = TRUE, maxrows = 10,showsampsize = TRUE, showeffN = FALSE)
```

### Fish Len Comps using `afscdata`

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="By manual inspection of the values and data plots, the outcomes are very similar, but not identical. It appears there is a slight squashing of observations towards older ages; the input sample sizes are essentially unchanged." }
SSplotComps(mod_2020_new_fsh_len_comps, kind = 'LEN',fleets = 1,  subplots = 1, datonly = TRUE, maxrows = 10,showsampsize = TRUE, showeffN = FALSE)

```

### Spawning Biomass, old vs new length comp data

```{r,  include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="The impact of the new age comps on model quantities, including spawning biomass and recruitment (and associated uncertainty) and survey fits, when passed to Model 18.2c, is trivial."}
SSplotComparisons(compsummary_2, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new length comp data'),
                  subplots = 2)
```

### Recruitment Time Series, old vs new length comp data

```{r, include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="The impact of the new age comps on model quantities, including spawning biomass and recruitment (and associated uncertainty) and survey fits, when passed to Model 18.2c, is trivial."}
SSplotComparisons(compsummary_2, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new length comp data'),
                  subplots = 12)
```

### Survey Fits, old vs new length comp data

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="The impact of the new age comps on model quantities, including spawning biomass and recruitment (and associated uncertainty) and survey fits, when passed to Model 18.2c, is trivial."}
SSplotComparisons(compsummary_2, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new length comp data'),
                  subplots = 13)
```

### Input Sample Sizes, Fishery Length Data

```{r, include=T, echo = FALSE, warning = FALSE, message= FALSE,fig.cap="The discrepancies between the number of hauls is more pronounced earlier in the time series; the afscdata() approach seems to have slightly higher values. This is likely due to filtration steps in the old code that I cannot test by hand. There are missing years in the 2000's because those data were not fit to (in lieu of age data)."}
mod_2020$lendbase %>% mutate(src = 'Old') %>%
  bind_rows(mod_2020_new_fsh_len_comps$lendbase%>% mutate(src = 'New')) %>%
  filter(Fleet == 1)%>%
  select(Yr, sex, Nsamp_in, Fleet, src) %>%
  group_by(Yr, Fleet, src) %>%
  summarise(inputN=mean(Nsamp_in)) %>%
  # mutate(Fleet = ifelse(Fleet == 1,'Fishery','Survey')) %>%
  ggplot(., aes(x = Yr, y = inputN, fill = src, color = src)) +
  geom_bar(position = 'dodge', stat = 'identity') +
  # facet_wrap(~Fleet, scales = 'free') +
  scale_fill_manual(values = colvec, labels = c('afscdata()','Model 18.2c (2020) data')) +
  scale_color_manual(values = colvec, labels = c('afscdata()','Model 18.2c (2020) data')) +
  labs(x = 'Year',  y = 'Input Sample Size (nhauls)', fill = '',color = '')
```
:::

## Fishery Age Compositions

The old datapull script and `afscdata` both read from `norpac.debriefed_spcomp`, though the latter reads from `mv` and the former doesn't. - Years 1994, 1995 and 1998 are not used in the model as length comp data are available. - The number of hauls is used as the input sample size; these values were recoverable for the age data using the `afscdata` approach, but the values for the length data are fairly different (see figure below). My guess is this has to do with updates to the database and/how filtration happens before compiling the comps. - The default `afscdata` approach did not have a means for getting sex-specific values for either comp dataset; I simply added these to the summary calls (ignoring unsexed fish) and reformatting things in SS3.

See the comments on the figures below for more information.

::: panel-tabset
### Fish Age Comps from 18.c (2020)

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="By manual inspection of the values and data plots, the outcomes are very similar, but not identical. It appears there is a slight squashing of observations towards older ages; the input sample sizes are essentially unchanged." }
SSplotComps(mod_2020, kind = 'AGE',fleets=1, subplots = 1, datonly = TRUE, maxrows = 6,showsampsize = TRUE, showeffN = FALSE)
```

### Fish Age Comps using `afscdata`

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="By manual inspection of the values and data plots, the outcomes are very similar, but not identical. It appears there is a slight squashing of observations towards older ages; the input sample sizes are essentially unchanged." }
SSplotComps(mod_2020_new_fsh_age_comps,fleets=1, kind = 'AGE', subplots = 1, datonly = TRUE, maxrows = 6,showsampsize = TRUE, showeffN = FALSE)

```

### Spawning Biomass, old vs new age data

```{r,  include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="The impact of the new age comps on model quantities, including spawning biomass and recruitment (and associated uncertainty) and survey fits, when passed to Model 18.2c, is trivial."}
SSplotComparisons(compsummary_1, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new comp data'),
                  subplots = 2)
```

### Recruitment Time Series, old vs new age data

```{r, include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="The impact of the new age comps on model quantities, including spawning biomass and recruitment (and associated uncertainty) and survey fits, when passed to Model 18.2c, is trivial."}
SSplotComparisons(compsummary_1, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new comp data'),
                  subplots = 12)
```

### Survey Fits, old vs new age data

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="The impact of the new age comps on model quantities, including spawning biomass and recruitment (and associated uncertainty) and survey fits, when passed to Model 18.2c, is trivial."}
SSplotComparisons(compsummary_1, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new age comp data'),
                  subplots = 13)
```




:::

**I am satisfied by this exploration that replacing the fishery compositional data with the outputs of `afscdata` does not have an unreasonable impact on model behavior, even given small changes in the observations.**

## Survey Biomass Data

From the 2020 SAFE:

> "This assessment used a single survey index of "total" *Hippoglossoides* spp. biomass that included the EBS “standard” survey areas and AI survey areas for the years 1982-2018. Survey biomass for *Hippoglossoides* spp. in the Aleutian Islands is very small as compared to that from the EBS shelf survey, and survey biomass for Bering flounder is very small as compared to that of flathead sole. A linear regression is used to estimate a relationship between EBS shelf *Hippoglossoides* spp. survey biomass estimates and AI survey biomass estimates; this relationship is used to estimate AI survey biomass in years when no AI survey occurred (by using the linear equation to find an AI biomass estimate in a particular year based on the EBS biomass estimate for that year)."

Both Dr. Monnohan (per his notes) and I are not thrilled with this approach, since being model-based means that even historical datapoints can change with each new observation (assuming that the output of the lm is used to replace the survey biomass series wholesale, which would be statistically prudent). It's also odd to me that the survey biomass data include both congeners while the compositional data does not; though it's important to remember that Bering flounder constitutes about 1% of catches.

I coded the linear model into the `afscdata::bsai_fhs` data extraction function and did *not* use the `afscassess::bts_biomass` function for further post-processing. The former function saves the Synthesis-formatted dataframe directly to `output/`. The resultant index is identical to what was used before.

```{r, include=FALSE, echo = FALSE, warning = FALSE}
mod_2020_new_srv_bio <- SS_output(here(year, 'model_runs','18.2c_2020_ss3v33022w-new_srv_biomass')) 
compsummary_b <- SSsummarize(list(mod_2020,mod_2020_new_srv_bio))
```

::: panel-tabset
 
#### Spawning Biomass, old vs new survey biomass data

```{r,  include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="No change in derived quantities."}
SSplotComparisons(compsummary_b, 
                  legendlabels = c('Model 18.2c (2020)',
                                   'Model 18.2c (2020) with new survey biomass data'),
                  subplots = 2)
```

#### Recruitment Time Series, old vs new survey biomass data
```{r, include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="No change in recruitment deviations."}
SSplotComparisons(compsummary_b, 
                  legendlabels = c('Model 18.2c (2020)',
                                   'Model 18.2c (2020) with new survey biomass data'),
                  subplots = 12)
```

#### Survey Fits, old vs new survey biomass data

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="Survey input data are identical and fits are the same."}
SSplotComparisons(compsummary_b, 
                  indexPlotEach = TRUE,
                  legendlabels = c('Model 18.2c (2020)',
                                   'Model 18.2c (2020) with new survey biomass data'),
                  subplots = 13)
```
:::


## Survey Compositional Data

### Survey CAALs

I went on a long journey to reproduce the survey compositional data, and came to the conclusion that it must be done using the material in the `gapindex` package, which is more faithful to what was provided in earlier years in the `HAEHNR` schema. My suspicion is that there is under-the-hood filtration and expansion that `afscdata` simply can't handle yet (at least for the BSAI), and going forward it is more sensible that we work with a tool that is maintained by the folks collecting the data. 

A deep dive into these issues is undertaken in R/2024_survey_comp_deepdive.qmd, and the lessons learned led to the development of a standalone workup script that 1) pulls from `gapindex` and 2) munges the appropriate sub tables in to the SS3-style compositional data. This replaces the long and redundant set of code that was developed for 2020. For simplicity, the plots here simply illustrate that we were able to get identical datasets and derived quantities using the new methods.


```{r, include=FALSE, echo = FALSE, warning = FALSE}
mod_2020_new_srv_caal <- SS_output(here(year, 'model_runs','18.2c_2020_ss3v33022w-new_srv_caal')) 
compsummary_3 <- SSsummarize(list(mod_2020,mod_2020_new_srv_caal))
```


::: panel-tabset
#### Survey CAALs from 18.c (2020)

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap= "Only trivial differences in this historical data provided to the original assessment (shown here) vs. those pulled using the gapindex package." }
SSplotComps(mod_2020,fleets=2, subplots = 3, kind = 'cond', 
            datonly = TRUE, maxrows = 6,showsampsize = TRUE, showeffN = FALSE)
```

#### Survey CAALs using `gapindex`

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="Only trivial differences in this historical data provided to the original assessment (previous tab) vs. those pulled using the gapindex package (shown here)." }
SSplotComps(mod_2020_new_srv_caal,fleets=2, subplots = 3, kind = 'cond',
            datonly = TRUE, maxrows = 6,showsampsize = TRUE, showeffN = FALSE)

```

#### Spawning Biomass, old vs new survey CAAL data

```{r,  include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="No change in derived quantities."}
SSplotComparisons(compsummary_3, 
                  legendlabels = c('Model 18.2c (2020)',
                                   'Model 18.2c (2020) with new CAAL data'),
                  subplots = 2)
```

#### Recruitment Time Series, new survey CAAL data

```{r, include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="No change in recruitment deviations."}
SSplotComparisons(compsummary_3, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new CAAL data'),
                  subplots = 12)
```

#### Survey Fits, old vs new survey CAAL data

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="The impact of the new age comps on model quantities, including spawning biomass and recruitment (and associated uncertainty) and survey fits, when passed to Model 18.2c, is trivial."}
SSplotComparisons(compsummary_3, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new CAAL data'),
                  subplots = 13)
```

#### Growth Curves, old vs new survey CAAL data

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="", out.width = "150%"}
par(mfrow = c(1,2))
SSplotBiology(mod_2020,subplots = 1)
SSplotBiology(mod_2020_new_srv_caal,subplots = 1) 
```
:::


## Survey Marginal Lengths
The input sample sizes are slightly different in the new datapull (from `gapindex`)

```{r, include=FALSE, echo = FALSE, warning = FALSE}
# mod_2020_new_srv_len <- SS_output(here(year, 'model_runs','18.2c_2020_ss3v33022w-new_srv_lengths'))
mod_2020_new_srv_len <- SS_output(here(year, 'model_runs','18.2c_2020_ss3v33022w-new_srv_len'))
compsummary_4 <- SSsummarize(list(mod_2020,mod_2020_new_srv_len))
```

::: panel-tabset
#### Survey lengths from 18.c (2020)

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap= "Only trivial differences in this historical data provided to the original assessment (shown here) vs. those pulled using  the gapindex package (next tab)." }
SSplotComps(mod_2020,fleets=2, subplots = 1, kind = 'LEN', 
            datonly = TRUE, maxrows = 6,showsampsize = TRUE, showeffN = FALSE)
```

#### Survey lengths using `afscdata`

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="Only trivial differences in this historical data provided to the original assessment (previous tab) vs. those pulled using the gapindex package (shown here)." }
SSplotComps(mod_2020_new_srv_len,fleets=2, subplots = 1, kind = 'LEN',
            datonly = TRUE, maxrows = 6,showsampsize = TRUE, showeffN = FALSE)

```

#### Spawning Biomass, old vs new survey lengths

```{r,  include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="No change in derived quantities."}
SSplotComparisons(compsummary_4, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new survey length data'),
                  subplots = 2)
```

#### Recruitment Time Series, new survey lengths

```{r, include=T, eval = TRUE, echo = FALSE, warning = FALSE, message =FALSE, fig.cap="No change in recruitment deviations."}
SSplotComparisons(compsummary_4, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new survey length data'),
                  subplots = 12)
```

#### Survey Fits, old vs new survey lengths

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap="The impact of the new age comps on model quantities, including spawning biomass and recruitment (and associated uncertainty) and survey fits, when passed to Model 18.2c, is trivial."}
SSplotComparisons(compsummary_4, 
                  legendlabels = c('Model 18.2c (2020)','Model 18.2c (2020) with new survey lengths'),
                  subplots = 13)
```

#### Growth Curves, old vs new survey lengths

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap=""}
par(mfrow = c(1,2))
SSplotBiology(mod_2020,subplots = 1)
SSplotBiology(mod_2020_new_srv_len,subplots = 1)
```
:::


## Survey Ages (ghosted)
These aren't used in the model but I wanted to confirm the pull from `afscdata` looked reasonable. Annoyingly, the SS3 plots for ghosted values aren't callable and the zoom is wrong, but these are satisfactory.

::: panel-tabset
### Ghosted Survey Ages from 18.c (2020)
```{r, include=FALSE, echo = FALSE, warning = FALSE}
mod_2020_new_srv_age <- SS_output(here(year, 'model_runs','18.2c_2020_ss3v33022w-new_srv_ages_ghost'))
compsummary_5 <- SSsummarize(list(mod_2020,mod_2020_new_srv_age))

```

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap= "Only trivial differences in this historical data provided to the original assessment (shown here) vs. those pulled using  the gapindex package (next tab)." }
knitr::include_graphics(here::here(old_mdl_fldr,'plots','comp_gstagedat_flt2mkt0.png'))
```

### Ghosted Survey Ages from `gapindex`

```{r, include=T, echo = FALSE, warning = FALSE, fig.cap= "Only trivial differences in this historical data provided to the original assessment (previous tab) vs. those pulled using  the gapindex package (shown here)." }
knitr::include_graphics(here::here(year, 'model_runs','18.2c_2020_ss3v33022w-new_srv_ages_ghost','plots','comp_gstagedat_flt2mkt0_page1.png'))
```

# Model Bridging

Importantly, the data updates conducted here are holistic, meaning that the entire time series of data for each component (where available) is replaced with what is currently available in the AKFIN database. A comparison between the data used in the last assessment and the latest version of that dataset is provided for each component above. The model that includes each change is named in the relevant header; these are hosted under `model_runs/`.

## Timeseries Prep

Some initial steps are required to model dynamics through the present year. These are as follows: - end year - selex - forecasting file/doesn't matter

## Adding Catches

## Adding Survey Biomass

## Adding Survey CAALs

## Adding Fishery Lengths

## Adding Fishery Ages

## Marginal Survey Ages & Lengths (ghosted)

# Bridged Operational Update Model, 18.2c (2024)

This is model 18.2c (2024) and represents an "operational update"; the model structure has not been modified, and only the input data have been revised to reflect the current database. Additional explorations with this model that extend beyond the scope of an "operational update" are provided in `2024_sensitivity_analysis.qmd`.
